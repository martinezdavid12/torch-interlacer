{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235cfabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f907864",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "sample = np.load(path, allow_pickle=True)\n",
    "print(list(sample.keys()))\n",
    "\n",
    "sample[\"axial_slice\"]\n",
    "plt.imshow(sample[\"axial_slice\"].T, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "\n",
    "# Import the model\n",
    "from torch_interlacer.models import get_interlacer_residual_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b438d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(Dataset):\n",
    "    \"\"\"Dataset for MRI slices with undersampling.\"\"\"\n",
    "    \n",
    "    def __init__(self, images, us_frac=0.75, input_domain='IMAGE', output_domain='IMAGE', transform=None, target_size=256):\n",
    "        self.images = images\n",
    "        self.us_frac = us_frac\n",
    "        self.input_domain = input_domain\n",
    "        self.output_domain = output_domain\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        # Create undersampling mask for target size\n",
    "        self.mask = self._create_undersampling_mask(target_size, us_frac)\n",
    "        \n",
    "    def _create_undersampling_mask(self, size, us_frac):\n",
    "        \"\"\"Create center-preserving undersampling mask.\"\"\"\n",
    "        mask = np.zeros((size, size), dtype=bool)\n",
    "        band_size = 40\n",
    "        center = size // 2\n",
    "        keep_band = (center - band_size//2, center + band_size//2)\n",
    "        \n",
    "        # Keep center band\n",
    "        mask[keep_band[0]:keep_band[1]+1, :] = True\n",
    "        \n",
    "        # Calculate how many extra lines to keep\n",
    "        total_lines = size\n",
    "        center_lines = keep_band[1] - keep_band[0] + 1\n",
    "        target_lines = int((1 - us_frac) * total_lines)\n",
    "        extra_lines = max(0, target_lines - center_lines)\n",
    "        \n",
    "        if extra_lines > 0:\n",
    "            # Randomly select extra lines from outside the center band\n",
    "            available_lines = (keep_band[0] - 0) + (size - keep_band[1] - 1)\n",
    "            if available_lines > 0:\n",
    "                extra_per_side = extra_lines // 2\n",
    "                lines_to_keep = np.random.choice(available_lines, min(extra_per_side, available_lines), replace=False)\n",
    "                \n",
    "                # Add lines above center band\n",
    "                above_lines = lines_to_keep[lines_to_keep < keep_band[0]]\n",
    "                mask[above_lines, :] = True\n",
    "                \n",
    "                # Add lines below center band  \n",
    "                below_lines = lines_to_keep[lines_to_keep >= keep_band[0]] - keep_band[0] + keep_band[1] + 1\n",
    "                below_lines = below_lines[below_lines < size]\n",
    "                mask[below_lines, :] = True\n",
    "        \n",
    "        return mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]  # Original image data\n",
    "        img = img.T\n",
    "        # Convert to complex and take FFT to simulate k-space acquisition\n",
    "        img_complex = img.astype(np.complex64)\n",
    "        kspace = np.fft.fftshift(np.fft.fft2(img_complex))\n",
    "        \n",
    "        # Apply undersampling mask\n",
    "        kspace_undersampled = kspace * self.mask\n",
    "        \n",
    "        # Convert back to image domain (corrupted image from undersampled k-space)\n",
    "        img_undersampled = np.fft.ifft2(np.fft.ifftshift(kspace_undersampled))\n",
    "        img_undersampled = np.real(img_undersampled)\n",
    "        \n",
    "        # Prepare input and output based on domains\n",
    "        if self.input_domain == 'IMAGE':\n",
    "            # Input: corrupted image (real + imaginary channels)\n",
    "            input_data = np.stack([img_undersampled, np.zeros_like(img_undersampled)], axis=0)\n",
    "        else:  # FREQ\n",
    "            # Input: undersampled k-space\n",
    "            input_data = np.stack([np.real(kspace_undersampled), np.imag(kspace_undersampled)], axis=0)\n",
    "        \n",
    "        if self.output_domain == 'IMAGE':\n",
    "            # Output: original clean image\n",
    "            output_data = np.stack([img, np.zeros_like(img)], axis=0)\n",
    "        else:  # FREQ\n",
    "            # Output: original k-space\n",
    "            output_data = np.stack([np.real(kspace), np.imag(kspace)], axis=0)\n",
    "        \n",
    "        return torch.from_numpy(input_data).float(), torch.from_numpy(output_data).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725a26ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mri_safe_resize(dataset, target=(256, 256)):\n",
    "    out_set = []\n",
    "    for x in dataset:\n",
    "        if x.shape == target:\n",
    "            pass\n",
    "        elif x.shape[0] < target[0]:\n",
    "            # add vertical padding\n",
    "            t_pad = (target[0] - x.shape[0]) // 2\n",
    "            b_pad = t_pad + (target[0] - x.shape[0]) % 2\n",
    "            # add horizontal padding\n",
    "            l_pad = (target[1] - x.shape[1]) // 2\n",
    "            r_pad = l_pad + (target[1] - x.shape[1]) % 2\n",
    "            # check upper\n",
    "            x = np.pad(x, pad_width=((t_pad, b_pad), (l_pad, r_pad)))\n",
    "        else:\n",
    "            # crop vertical\n",
    "            t_crop = (x.shape[0] - target[0]) // 2\n",
    "            b_crop = t_crop + (x.shape[0] - target[0]) % 2\n",
    "            l_crop = (x.shape[1] - target[1]) // 2\n",
    "            r_crop = l_crop + (x.shape[1] - target[1]) % 2\n",
    "            # crop horizontal \n",
    "            x = x[t_crop:-b_crop, l_crop:-r_crop]\n",
    "        out_set.append(x)\n",
    "    return out_set\n",
    "\n",
    "def normalize(dataset):\n",
    "    # since arrays are normalized at this point, we can take mean of means without weights\n",
    "    s = 0\n",
    "    mx = dataset[0].flatten()[0]\n",
    "    for i in range(len(dataset)):\n",
    "        x = dataset[i]\n",
    "        s += x.mean()\n",
    "        cur_mx = x.max()\n",
    "        if cur_mx > mx:\n",
    "            mx = cur_mx\n",
    "    mean = s / len(dataset)\n",
    "    # normalize\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = (dataset[i] - mean)/ mx\n",
    "    return dataset\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d10651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "TEST_SPLIT = 0.2\n",
    "\n",
    "slice_files = glob.glob(\"data/combined_slices/*.npz\")\n",
    "print(slice_files)\n",
    "temp = slice_files[0]\n",
    "a = np.load(temp)\n",
    "print(f\"keys: {list(a.keys())}\")\n",
    "\n",
    "all_data = []\n",
    "for fname in slice_files:\n",
    "    all_data.append(np.load(fname)[\"axial_slice\"])\n",
    "\n",
    "print(f\"size of dataset: {len(all_data)}\")\n",
    "\n",
    "n = len(all_data)\n",
    "indices = np.arange(0, n)\n",
    "np.random.shuffle(indices)\n",
    "test_idxs = set(indices[:int(n * TEST_SPLIT)])\n",
    "train_idxs = set(indices[int(n * TEST_SPLIT):])\n",
    "\n",
    "test_data = [all_data[i].astype(np.float32) for i in test_idxs]\n",
    "train_data = [all_data[i].astype(np.float32) for i in train_idxs]\n",
    "\n",
    "test_data = mri_safe_resize(test_data)\n",
    "train_data = mri_safe_resize(train_data)\n",
    "\n",
    "test_data = normalize(test_data)\n",
    "train_data = normalize(train_data)\n",
    "\n",
    "\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5fdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and train configs\n",
    "batch_size = 16\n",
    "us_frac = 0.4\n",
    "input_domain = 'FREQ'\n",
    "output_domain = 'FREQ'\n",
    "lr = 0.001\n",
    "num_epochs = 20\n",
    "\n",
    "# Load data (comment out if you don't have data yet)\n",
    "train_images, val_images = test_data, train_data\n",
    "train_dataset = MRIDataset(train_images, us_frac, input_domain, output_domain, transform=None)\n",
    "val_dataset = MRIDataset(val_images, us_frac, input_domain, output_domain, transform=None)\n",
    "val_dataset.mask = train_dataset.mask # share masks\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d4a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 7))\n",
    "input_sample, output_sample = train_dataset[0]\n",
    "\n",
    "print(input_sample.shape)\n",
    "print(output_sample.shape)\n",
    "axes[0].imshow(input_sample[0].numpy().squeeze(), cmap=\"gray\")\n",
    "axes[0].set_title(\"Corruped Frequency Space - Axial Slice\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "corrupt = torch.fft.ifft2(torch.fft.ifftshift(torch.complex(input_sample[0], input_sample[1])))\n",
    "# corrupt = corrupt.real / torch.max(corrupt.real)\n",
    "axes[1].imshow(corrupt.real, cmap=\"gray\")\n",
    "axes[1].set_title(\"Corrupted Image\")\n",
    "axes[1].axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = get_interlacer_residual_model(\n",
    "    input_size=(2, 256, 256),\n",
    "    nonlinearity='3-piece',\n",
    "    kernel_size=9,\n",
    "    num_features=32,\n",
    "    num_convs=1,\n",
    "    num_layers=10\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "print(f\"Model created and moved to {device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss function and optimizer\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item():.6f}')\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate for one epoch.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1434253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"New best model saved! Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Best validation loss: {best_val_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    max_pixel = 1.0\n",
    "    return 20 * np.log10(max_pixel / np.sqrt(mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6c2223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['figure.facecolor'] = 'white'  # figure bg\n",
    "mpl.rcParams['axes.facecolor']   = 'white'  # axes bg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e7e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 10))\n",
    "input_sample, output_sample = val_dataset[131]\n",
    "print(input_sample.shape)\n",
    "print(output_sample.shape)\n",
    "gt_tensor = output_sample.cpu().detach().squeeze()\n",
    "gt_img = torch.fft.ifft2(torch.fft.ifftshift(torch.complex(gt_tensor[0], gt_tensor[1])))\n",
    "gt_img = gt_img.real\n",
    "axes[0].imshow(gt_img.numpy(), cmap=\"gray\")\n",
    "axes[0].set_title(\"Validation Set Axial Slice - GT\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "psnr_corrupt = get_psnr(gt_img.numpy(), corrupt.numpy())\n",
    "corrupt = torch.fft.ifft2(torch.fft.ifftshift(torch.complex(input_sample[0], input_sample[1]))).real\n",
    "psnr_corrupt = get_psnr(gt_img.numpy(), corrupt.numpy())\n",
    "axes[1].imshow(corrupt.real, cmap=\"gray\")\n",
    "axes[1].set_title(f\"Corrupted Image - PSNR: {psnr_corrupt:.4f}\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    recon = model(input_sample.unsqueeze(0).to(device))\n",
    "    recon = recon.cpu().detach().squeeze()\n",
    "    print(recon.shape)\n",
    "    recon_img = torch.fft.ifft2(torch.fft.ifftshift(torch.complex(recon[0], recon[1]))).real\n",
    "    psnr_recon = get_psnr(gt_img.numpy(), recon_img.numpy().astype(np.float32))\n",
    "    axes[2].imshow(recon_img.numpy(), cmap=\"gray\")\n",
    "    axes[2].set_title(f\"Reconstructed Image - PSNR: {psnr_recon:.4f}\")\n",
    "    axes[2].axis(\"off\")\n",
    "    \n",
    "print(get_psnr(gt_img.numpy(), corrupt.numpy()))\n",
    "print(get_psnr(gt_img.numpy(), recon_img.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935de7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gt_img - corrupt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d520d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gt_img - recon_img.real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875cc59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(corrupt - recon_img.real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d82322c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
